Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Bouzy2007,
abstract = {This paper describes experiments using reinforcement learning techniques to compute pattern urgencies used during simulations performed in a Monte-Carlo Go architecture. Currently, Monte-Carlo is a popular technique for computer Go. In a previous study, Monte-Carlo was associated with domain-dependent knowledge in the Go-playing program Indigo. In 2003, a 3times3 pattern database was built manually. This paper explores the possibility of using reinforcement learning to automatically tune the 3times3 pattern urgencies. On 9times9 boards, within the Monte-Carlo architecture of Indigo, the result obtained by our automatic learning experiments is better than the manual method by a 3-point margin on average, which is satisfactory. Although the current results are promising on 19times19 boards, obtaining strictly positive results with such a large size remains to be done},
author = {Bouzy, Bruno and Chaslot, Guillaume},
doi = {10.1109/CIG.2006.311699},
file = {:Users/sepmein/Qsync/Papers/Bouzy, Chaslot{\_}2007{\_}Monte-Carlo Go reinforcement learning experiments.pdf:pdf},
isbn = {1424404649},
journal = {Proceedings of the 2006 IEEE Symposium on Computational Intelligence and Games, CIG'06},
keywords = {Computer Go,Monte-Carlo,Reinforcement learning},
pages = {187--194},
title = {{Monte-Carlo Go reinforcement learning experiments}},
year = {2007}
}
