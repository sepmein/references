Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Graves2014,
abstract = {This paper presents a speech recognition system that directly transcribes audio data with text, without requiring an intermediate phonetic representation. The system is based on a combination of the deep bidirectional LSTM recurrent neural network architecture and the Connectionist Temporal Classification objective function. A modification to the objective function is introduced that trains the network to minimise the expectation of an arbitrary transcription loss function. This allows a direct optimisation of the word error rate, even in the absence of a lexicon or language model. The system achieves a word error rate of 27.3{\%} on the Wall Street Journal corpus with no prior linguistic information, 21.9{\%} with only a lexicon of allowedwords, and 8.2{\%} with a trigram language model. Combining the network with a baseline system further reduces the error rate to 6.7{\%}.},
archivePrefix = {arXiv},
arxivId = {1512.02595},
author = {Graves, Alex and Jaitly, Navdeep},
doi = {10.1145/1143844.1143891},
eprint = {1512.02595},
file = {:Users/sepmein/Qsync/Papers/Graves, Jaitly{\_}2014{\_}Towards End-To-End Speech Recognition with Recurrent Neural Networks.pdf:pdf},
isbn = {1595933832},
issn = {10987576},
journal = {JMLR Workshop and Conference Proceedings},
number = {1},
pages = {1764--1772},
pmid = {1000285842},
title = {{Towards End-To-End Speech Recognition with Recurrent Neural Networks}},
url = {http://jmlr.org/proceedings/papers/v32/graves14.pdf{\%}5Cnhttp://www.jmlr.org/proceedings/papers/v32/graves14.html},
volume = {32},
year = {2014}
}
