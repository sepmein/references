Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Parisotto2015,
abstract = {The ability to act in multiple environments and transfer previous knowledge to new situations can be considered a critical aspect of any intelligent agent. Towards this goal, we define a novel method of multitask and transfer learning that enables an autonomous agent to learn how to behave in multiple tasks simultaneously, and then generalize its knowledge to new domains. This method, termed "Actor-Mimic", exploits the use of deep reinforcement learning and model compression techniques to train a single policy network that learns how to act in a set of distinct tasks by using the guidance of several expert teachers. We then show that the representations learnt by the deep policy network are capable of generalizing to new tasks with no prior expert guidance, speeding up learning in novel environments. Although our method can in general be applied to a wide range of problems, we use Atari games as a testing environment to demonstrate these methods.},
archivePrefix = {arXiv},
arxivId = {1511.06342},
author = {Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
eprint = {1511.06342},
file = {:Users/sepmein/Qsync/Papers/Parisotto, Ba, Salakhutdinov{\_}2015{\_}Actor-Mimic Deep Multitask and Transfer Reinforcement Learning.pdf:pdf},
pages = {1--16},
title = {{Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning}},
url = {http://arxiv.org/abs/1511.06342},
year = {2015}
}
