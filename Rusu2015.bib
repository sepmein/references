Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Rusu2015,
abstract = {Policies for complex visual tasks have been successfully learned with deep reinforcement learning, using an approach called deep Q-networks (DQN), but relatively large (task-specific) networks and extensive training are needed to achieve good performance. In this work, we present a novel method called policy distillation that can be used to extract the policy of a reinforcement learning agent and train a new network that performs at the expert level while being dramatically smaller and more efficient. Furthermore, the same method can be used to consolidate multiple task-specific policies into a single policy. We demonstrate these claims using the Atari domain and show that the multi-task distilled agent outperforms the single-task teachers as well as a jointly-trained DQN agent.},
archivePrefix = {arXiv},
arxivId = {1511.06295},
author = {Rusu, Andrei A. and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
doi = {10.1038/nature14236},
eprint = {1511.06295},
file = {:Users/sepmein/Qsync/Papers/Rusu et al.{\_}2015{\_}Policy Distillation.pdf:pdf},
isbn = {978-1-4799-0356-6},
issn = {0028-0836},
pages = {1--13},
pmid = {25719670},
title = {{Policy Distillation}},
url = {http://arxiv.org/abs/1511.06295},
year = {2015}
}
