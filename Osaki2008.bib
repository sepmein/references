Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Osaki2008,
abstract = {This paper presents a new reinforcement learning method, called temporal difference learning with Monte Carlo simulation (TDMC), which uses a combination of Temporal Difference Learning (TD) and winning probability in each non-terminal position. Studies on self-teaching evaluation functions as applied to logic games have been conducted for many years, however few successful results of employing TD have been reported. This is perhaps due to the fact that the only reward observable in logic games is their final outcome, with no obvious rewards present in non-terminal positions. TDMC(lambda) attempts to compensate this problem by introducing winning probabilities, obtained through Monte Carlo simulation, as substitute rewards. Using Othello as a testing environment, TDMC(lambda), in comparison to TD(lambda), has been seen to yield better learning results.},
author = {Osaki, Yasuhiro and Shibahara, Kazutomo and Tajima, Yasuhiro and Kotani, Yoshiyuki},
doi = {10.1109/CIG.2008.5035641},
file = {:Users/sepmein/Qsync/Papers/Osaki et al.{\_}2008{\_}An Othello evaluation function based on Temporal Difference Learning using probability of winning.pdf:pdf},
isbn = {978-1-4244-2973-8},
issn = {10162291},
journal = {2008 IEEE Symposium On Computational Intelligence and Games},
pages = {205--211},
pmid = {1822132},
title = {{An Othello evaluation function based on Temporal Difference Learning using probability of winning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5035641{\%}5Cnhttp://www.csse.uwa.edu.au/cig08/Proceedings/papers/8010.pdf},
year = {2008}
}
