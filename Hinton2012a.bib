Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Hinton2012a,
abstract = {Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.},
archivePrefix = {arXiv},
arxivId = {1207.0580},
author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and Kingsbury, Brian},
doi = {10.1109/MSP.2012.2205597},
eprint = {1207.0580},
file = {:Users/sepmein/Qsync/Papers/Hinton et al.{\_}2012{\_}Deep Neural Networks for Acoustic Modeling in Speech Recognition.pdf:pdf},
isbn = {1053-5888},
issn = {1053-5888},
journal = {IEEE Signal Processing Magazine},
number = {November},
pages = {82--97},
pmid = {13057166},
title = {{Deep Neural Networks for Acoustic Modeling in Speech Recognition}},
year = {2012}
}
