Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Farhadi2010,
abstract = {Humans can prepare concise descriptions of pictures, focus- ing on what they find important.We demonstrate that automatic meth- ods can do so too.We describe a system that can compute a score linking an image to a sentence. This score can be used to attach a descriptive sentence to a given image, or to obtain images that illustrate a given sentence. The score is obtained by comparing an estimate of meaning ob- tained from the image to one obtained from the sentence. Each estimate of meaning comes from a discriminative procedure that is learned us- ing data. We evaluate on a novel dataset consisting of human-annotated images. While our underlying estimate of meaning is impoverished, it is sufficient to produce very good quantitative results, evaluated with a novel score that can account for synecdoche.},
author = {Farhadi, Ali and Hejrati, Mohsen and Sadeghi, Mohammad Amin and Young, Peter and Rashtchian, Cyrus and Hockenmaier, Julia and Forsyth, David},
doi = {10.1007/978-3-642-15561-1_2},
file = {:Users/sepmein/Qsync/Papers/Farhadi et al.{\_}2010{\_}Every picture tells a story Generating sentences from images.pdf:pdf},
isbn = {364215560X},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 4},
pages = {15--29},
title = {{Every picture tells a story: Generating sentences from images}},
volume = {6314 LNCS},
year = {2010}
}
